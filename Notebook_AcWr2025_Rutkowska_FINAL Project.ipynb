{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1485931f",
   "metadata": {},
   "source": [
    "# Readability of NATO Military Documents for Non-Aviation Personnel\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook presents a comprehensive readability analysis of NATO air-to-air refuelling (AAR) doctrinal materials. The primary goal is to evaluate whether the language and textual complexity of these documents are accessible to personnel outside the aviation domain, such as logisticians, allied planners, and military translators. Clear inter-branch and multinational communication is essential in joint operations. Therefore, understanding the accessibility of doctrinal texts is a key aspect of operational effectiveness.\n",
    "\n",
    "## Background\n",
    "\n",
    "Air-to-air refuelling (AAR) is a sophisticated logistical procedure governed by official NATO doctrines including ATP-3.3.4.5 and its supplementary publications. These texts provide standardized terminology and procedures for refuelling operations but are often dense with technical jargon. The analysis presented in this notebook uses publicly available NATO material to emulate a readability study.\n",
    "\n",
    "The following readability metrics were selected for their wide use in textual evaluation:\n",
    "\n",
    "- **Flesch Reading Ease**\n",
    "- **Gunning Fog Index**\n",
    "- **SMOG Index**\n",
    "\n",
    "---\n",
    "\n",
    "## Document Preview\n",
    "\n",
    "![NATO Tanker Refuelling Operation](KC135_refueling.jpg)  \n",
    "*Source: KC-135 refuelling E-8 JSTARS – U.S. Air Force*\n",
    "\n",
    "## Tools and Libraries Used\n",
    "\n",
    "- `requests` – to retrieve HTML content  \n",
    "- `BeautifulSoup` – for HTML parsing and text extraction  \n",
    "- `textstat` – to calculate readability indices  \n",
    "- `matplotlib` – for data visualization  \n",
    "- `pandas` – to structure results  \n",
    "\n",
    "---\n",
    "\n",
    "## Web Scraping of Doctrinal Sample Text\n",
    "\n",
    "Since many official NATO documents are not publicly accessible, this analysis demonstrates scraping from an open-access NATO website. The content serves as a proxy for doctrinal text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1a2837",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.nato.int/cps/en/natolive/topics_49111.htm\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract paragraph text\n",
    "paragraphs = soup.find_all(\"p\")\n",
    "text_content = \" \".join([p.get_text() for p in paragraphs])\n",
    "\n",
    "# Display preview of the scraped text\n",
    "print(text_content[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed82fc1",
   "metadata": {},
   "source": [
    "## Readability Analysis of Scraped Text\n",
    "\n",
    "Using the scraped content, we calculate the following readability scores to estimate textual accessibility for general audiences and non-specialist personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc708096",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "flesch = textstat.flesch_reading_ease(text_content)\n",
    "fog = textstat.gunning_fog(text_content)\n",
    "smog = textstat.smog_index(text_content)\n",
    "\n",
    "print(\"Flesch Reading Ease:\", flesch)\n",
    "print(\"Gunning Fog Index:\", fog)\n",
    "print(\"SMOG Index:\", smog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16317d8b",
   "metadata": {},
   "source": [
    "## Visualization of Readability Metrics\n",
    "\n",
    "The bar chart below visualizes the scores calculated from the NATO article to facilitate interpretation and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d82849a",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = {\n",
    "    \"Flesch Reading Ease\": flesch,\n",
    "    \"Gunning Fog Index\": fog,\n",
    "    \"SMOG Index\": smog\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(scores.keys(), scores.values())\n",
    "plt.title(\"Readability Scores of NATO Web Text\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef84c989",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates a practical application of readability metrics to NATO-related documentation. While the example uses publicly available web content, the methodology can be directly applied to classified or internal doctrinal materials when appropriate access is available. The initial results suggest that such documents may contain linguistic features that hinder accessibility for personnel not specialized in aviation or operations. \n",
    "\n",
    "Future work may include a comparative study across different types of military documents, use of lexical complexity tools (such as TAALES or LCA), and annotation of terms that require simplification. The goal is to enhance clarity and accessibility without compromising operational precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
